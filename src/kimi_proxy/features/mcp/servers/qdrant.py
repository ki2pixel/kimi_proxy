"""
Client MCP sp√©cialis√© pour Qdrant.

G√®re les op√©rations de recherche s√©mantique, clustering et gestion de vecteurs m√©moire.
Performance: <50ms pour la recherche s√©mantique.
"""
from datetime import datetime
from typing import Dict, Any, List, Optional

from ....core.tokens import count_tokens_text
from ..base.rpc import MCPRPCClient

# Mod√®les imports avec TYPE_CHECKING pour √©viter les cycles
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from kimi_proxy.core.models import QdrantSearchResult, MCPCluster, MCPExternalServerStatus
    from ..base.config import MCPClientConfig


class QdrantMCPClient:
    """
    Client sp√©cialis√© pour Qdrant MCP.
    
    Supporte:
    - Recherche s√©mantique avec similarit√©
    - Stockage de vecteurs m√©moire
    - D√©tection de contenu redondant
    - Clustering de m√©moires par session
    
    Performance:
    - Recherche: <50ms
    - Upsert: <100ms
    - Clustering: <2s
    """
    
    def __init__(self, config: "MCPClientConfig", rpc_client: MCPRPCClient):
        """
        Initialise le client Qdrant MCP.
        
        Args:
            config: Configuration MCP
            rpc_client: Client RPC de base
        """
        self.config = config
        self.rpc_client = rpc_client
        # Cache du statut pour √©viter les appels r√©p√©t√©s
        self._status: Optional["MCPExternalServerStatus"] = None
        self._status_check_time: Optional[datetime] = None
        self._status_ttl_seconds = 30  # Cache statut pour 30s
    
    async def check_status(self) -> "MCPExternalServerStatus":
        """
        V√©rifie le statut du serveur Qdrant MCP.

        Utilise un cache TTL de 30 secondes pour √©viter les appels r√©p√©t√©s.
        Pour les instances cloud, assume toujours connect√© (g√©r√© par Qdrant).

        Returns:
            Status du serveur Qdrant
        """
        from kimi_proxy.core.models import MCPExternalServerStatus

        # V√©rifie le cache TTL
        now = datetime.now()
        if (self._status_check_time and
            (now - self._status_check_time).total_seconds() < self._status_ttl_seconds):
            return self._status

        import logging
        logger = logging.getLogger(__name__)

        # D√©tecte si c'est une instance cloud (URL contient cloud.qdrant.io)
        is_cloud = "cloud.qdrant.io" in self.config.qdrant_url

        if is_cloud:
            logger.info(f"‚òÅÔ∏è Qdrant cloud detected: {self.config.qdrant_url}")
            logger.info("‚úÖ Assuming cloud Qdrant is always connected (managed service)")

            # Pour le cloud, assume toujours connect√© avec latence simul√©e
            self._status = MCPExternalServerStatus(
                name="qdrant-mcp",
                type="qdrant",
                url=self.config.qdrant_url,
                connected=True,  # Cloud est toujours disponible
                last_check=datetime.now().isoformat(),
                latency_ms=50.0,  # Latence typique cloud
                capabilities=["semantic_search", "vector_store", "clustering"]
            )
            self._status_check_time = now
            return self._status

        # Pour les instances locales, v√©rifie le statut via health check
        try:
            start_time = datetime.now()
            client = await self.rpc_client._get_client()

            # En-t√™tes avec API key si configur√©e
            headers = {}
            if self.config.qdrant_api_key:
                headers["api-key"] = self.config.qdrant_api_key

            logger.info(f"üîç Checking Qdrant status at URL: {self.config.qdrant_url}")
            logger.info(f"üîë Using API key: {'Yes' if self.config.qdrant_api_key else 'No'}")

            # Ping Qdrant /healthz endpoint
            response = await client.get(
                f"{self.config.qdrant_url}/healthz",
                headers=headers,
                timeout=2.0
            )

            logger.info(f"üì° Qdrant health check response: {response.status_code}")

            latency_ms = (datetime.now() - start_time).total_seconds() * 1000
            connected = response.status_code == 200

            logger.info(f"‚úÖ Qdrant status: connected={connected}, latency={latency_ms:.2f}ms")

            # Met √† jour le cache
            self._status = MCPExternalServerStatus(
                name="qdrant-mcp",
                type="qdrant",
                url=self.config.qdrant_url,
                connected=connected,
                last_check=datetime.now().isoformat(),
                latency_ms=latency_ms,
                capabilities=["semantic_search", "vector_store", "clustering"]
            )
            self._status_check_time = now

            return self._status

        except Exception as e:
            logger.error(f"‚ùå Qdrant status check failed: {str(e)}")
            logger.error(f"üîó URL attempted: {self.config.qdrant_url}/healthz")

            # Cache l'erreur
            self._status = MCPExternalServerStatus(
                name="qdrant-mcp",
                type="qdrant",
                url=self.config.qdrant_url,
                connected=False,
                last_check=datetime.now().isoformat(),
                error_count=1,
                capabilities=[]
            )
            self._status_check_time = now
            return self._status
    
    async def search_similar(
        self, 
        query: str, 
        limit: int = 5,
        score_threshold: float = 0.7
    ) -> List["QdrantSearchResult"]:
        """
        Recherche s√©mantique via Qdrant MCP.
        
        Performance cible: <50ms
        
        Args:
            query: Texte de requ√™te (max 500 chars recommand√©)
            limit: Nombre maximum de r√©sultats (par d√©faut: 5)
            score_threshold: Seuil de similarit√© (0-1, par d√©faut: 0.7)
            
        Returns:
            Liste des r√©sultats de recherche tri√©s par score d√©croissant
            
        Example:
            >>> results = await client.search_similar(
            ...     "comment impl√©menter une API",
            ...     limit=3,
            ...     score_threshold=0.75
            ... )
            >>> print(f"{len(results)} r√©sultats pertinents")
        """
        result = await self.rpc_client.make_rpc_call(
            server_url=self.config.qdrant_url,
            method="search",
            params={
                "collection": self.config.qdrant_collection,
                "query": query,
                "limit": limit,
                "score_threshold": score_threshold
            },
            timeout_ms=self.config.search_timeout_ms,
            api_key=self.config.qdrant_api_key
        )
        
        if not result:
            return []
        
        from kimi_proxy.core.models import QdrantSearchResult
        
        hits = result.get("hits", [])
        return [
            QdrantSearchResult(
                id=hit.get("id", ""),
                score=hit.get("score", 0.0),
                content_preview=hit.get("payload", {}).get("preview", "")[:200],
                full_content=hit.get("payload", {}).get("content", ""),
                metadata=hit.get("payload", {}).get("metadata", {}),
                vector=hit.get("vector")
            )
            for hit in hits
        ]
    
    async def store_vector(
        self, 
        content: str, 
        memory_type: str = "episodic",
        metadata: Optional[Dict[str, Any]] = None
    ) -> Optional[str]:
        """
        Stocke un vecteur m√©moire dans Qdrant.
        
        G√©n√®re un ID unique bas√© sur le hash du contenu.
        
        Args:
            content: Contenu √† stocker (texte)
            memory_type: Type de m√©moire (episodic/frequent/semantic)
            metadata: M√©tadonn√©es additionnelles (optionnel)
            
        Returns:
            ID du vecteur stock√© ou None si √©chec
            
        Example:
            >>> vector_id = await client.store_vector(
            ...     "J'ai d√©bogu√© l'API ce matin",
            ...     memory_type="episodic",
            ...     metadata={"session_id": 1, "timestamp": "2026-02-18"}
            ... )
        """
        result = await self.rpc_client.make_rpc_call(
            server_url=self.config.qdrant_url,
            method="upsert",
            params={
                "collection": self.config.qdrant_collection,
                "points": [{
                    "id": self._generate_vector_id(content, memory_type),
                    "vector": None,  # Qdrant g√©n√®re l'embedding
                    "payload": {
                        "content": content,
                        "preview": content[:200],
                        "type": memory_type,
                        "metadata": metadata or {},
                        "timestamp": datetime.now().isoformat()
                    }
                }]
            },
            timeout_ms=1000.0,
            api_key=self.config.qdrant_api_key
        )
        
        if not result:
            return None
        
        return result.get("id") if isinstance(result, dict) else None
    
    async def find_redundant(
        self, 
        content: str, 
        similarity_threshold: float = 0.85
    ) -> List[str]:
        """
        D√©tecte les m√©moires redondantes (similarit√© √©lev√©e).
        
        Args:
            content: Contenu √† v√©rifier
            similarity_threshold: Seuil de similarit√© (0-1, par d√©faut: 0.85)
            
        Returns:
            Liste des IDs de m√©moires redondantes trouv√©es
            
        Example:
            >>> redundant = await client.find_redundant(
            ...     "J'ai d√©bogu√© l'API ce matin",
            ...     similarity_threshold=0.90
            ... )
            >>> if redundant:
            ...     print(f"{len(redundant)} m√©moires similaires trouv√©es")
        """
        similar = await self.search_similar(
            query=content[:500],  # Limite pour performance
            limit=10,
            score_threshold=similarity_threshold
        )
        return [s.id for s in similar if s.score >= similarity_threshold]
    
    async def cluster_memories(
        self, 
        session_id: int,
        min_cluster_size: int = 3
    ) -> List["MCPCluster"]:
        """
        Clusterise les m√©moires d'une session par similarit√©.
        
        Performance: <2s pour 1000+ m√©moires
        
        Args:
            session_id: ID de la session √† clusteriser
            min_cluster_size: Nombre minimum de points par cluster (par d√©faut: 3)
            
        Returns:
            Liste des clusters avec leurs m√©triques
            
        Example:
            >>> clusters = await client.cluster_memories(session_id=42)
            >>> for cluster in clusters:
            ...     print(f"Topic: {cluster.topic_label}")
            ...     print(f"Cohesion: {cluster.cohesion_score:.2f}")
        """
        from kimi_proxy.core.models import MCPCluster
        
        result = await self.rpc_client.make_rpc_call(
            server_url=self.config.qdrant_url,
            method="cluster",
            params={
                "collection": self.config.qdrant_collection,
                "filter": {"session_id": session_id},
                "min_cluster_size": min_cluster_size
            },
            timeout_ms=2000.0,
            api_key=self.config.qdrant_api_key
        )
        
        if not result or not isinstance(result, dict):
            return []
        
        clusters = result.get("clusters", [])
        return [
            MCPCluster(
                id=c.get("id", ""),
                center_id=c.get("center_id", ""),
                memory_ids=c.get("point_ids", []),
                centroid=c.get("centroid"),
                cohesion_score=c.get("cohesion", 0.0),
                topic_label=c.get("topic", "")
            )
            for c in clusters
        ]
    
    def is_available(self) -> bool:
        """
        V√©rifie si Qdrant est disponible (bas√© sur le cache).
        
        Returns:
            True si le dernier statut √©tait connect√©
        """
        return self._status is not None and self._status.connected
    
    def _generate_vector_id(self, content: str, memory_type: str) -> str:
        """
        G√©n√®re un ID unique pour le vecteur.
        
        Utilise hash pour g√©n√©rer un ID stable.
        
        Args:
            content: Contenu √† stocker
            memory_type: Type de m√©moire
            
        Returns:
            ID unique au format "type_hash32"
        """
        import hashlib
        content_hash = hashlib.md5(content.encode()).hexdigest()[:8]
        return f"{memory_type}_{content_hash}"
