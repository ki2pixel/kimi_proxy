"""
Client MCP spécialisé pour Qdrant.

Gère les opérations de recherche sémantique, clustering et gestion de vecteurs mémoire.
Performance: <50ms pour la recherche sémantique.
"""
from datetime import datetime
from typing import Dict, Any, List, Optional

from ....core.tokens import count_tokens_text
from ..base.rpc import MCPRPCClient

# Modèles imports avec TYPE_CHECKING pour éviter les cycles
from typing import TYPE_CHECKING

if TYPE_CHECKING:
    from kimi_proxy.core.models import QdrantSearchResult, MCPCluster, MCPExternalServerStatus
    from ..base.config import MCPClientConfig


class QdrantMCPClient:
    """
    Client spécialisé pour Qdrant MCP.
    
    Supporte:
    - Recherche sémantique avec similarité
    - Stockage de vecteurs mémoire
    - Détection de contenu redondant
    - Clustering de mémoires par session
    
    Performance:
    - Recherche: <50ms
    - Upsert: <100ms
    - Clustering: <2s
    """
    
    def __init__(self, config: "MCPClientConfig", rpc_client: MCPRPCClient):
        """
        Initialise le client Qdrant MCP.
        
        Args:
            config: Configuration MCP
            rpc_client: Client RPC de base
        """
        self.config = config
        self.rpc_client = rpc_client
        # Cache du statut pour éviter les appels répétés
        self._status: Optional["MCPExternalServerStatus"] = None
        self._status_check_time: Optional[datetime] = None
        self._status_ttl_seconds = 30  # Cache statut pour 30s
    
    async def check_status(self) -> "MCPExternalServerStatus":
        """
        Vérifie le statut du serveur Qdrant MCP.
        
        Utilise un cache TTL de 30 secondes pour éviter les appels répétés.
        
        Returns:
            Status du serveur Qdrant
        """
        from kimi_proxy.core.models import MCPExternalServerStatus
        
        # Vérifie le cache TTL
        now = datetime.now()
        if (self._status_check_time and 
            (now - self._status_check_time).total_seconds() < self._status_ttl_seconds):
            return self._status
        
        try:
            start_time = datetime.now()
            client = await self.rpc_client._get_client()
            
            # En-têtes avec API key si configurée
            headers = {}
            if self.config.qdrant_api_key:
                headers["api-key"] = self.config.qdrant_api_key
            
            # Ping Qdrant /healthz endpoint
            response = await client.get(
                f"{self.config.qdrant_url}/healthz",
                headers=headers,
                timeout=2.0
            )
            
            latency_ms = (datetime.now() - start_time).total_seconds() * 1000
            connected = response.status_code == 200
            
            # Met à jour le cache
            self._status = MCPExternalServerStatus(
                name="qdrant-mcp",
                type="qdrant",
                url=self.config.qdrant_url,
                connected=connected,
                last_check=datetime.now().isoformat(),
                latency_ms=latency_ms,
                capabilities=["semantic_search", "vector_store", "clustering"]
            )
            self._status_check_time = now
            
            return self._status
            
        except Exception as e:
            # Cache l'erreur
            self._status = MCPExternalServerStatus(
                name="qdrant-mcp",
                type="qdrant",
                url=self.config.qdrant_url,
                connected=False,
                last_check=datetime.now().isoformat(),
                error_count=1,
                capabilities=[]
            )
            self._status_check_time = now
            return self._status
    
    async def search_similar(
        self, 
        query: str, 
        limit: int = 5,
        score_threshold: float = 0.7
    ) -> List["QdrantSearchResult"]:
        """
        Recherche sémantique via Qdrant MCP.
        
        Performance cible: <50ms
        
        Args:
            query: Texte de requête (max 500 chars recommandé)
            limit: Nombre maximum de résultats (par défaut: 5)
            score_threshold: Seuil de similarité (0-1, par défaut: 0.7)
            
        Returns:
            Liste des résultats de recherche triés par score décroissant
            
        Example:
            >>> results = await client.search_similar(
            ...     "comment implémenter une API",
            ...     limit=3,
            ...     score_threshold=0.75
            ... )
            >>> print(f"{len(results)} résultats pertinents")
        """
        result = await self.rpc_client.make_rpc_call(
            server_url=self.config.qdrant_url,
            method="search",
            params={
                "collection": self.config.qdrant_collection,
                "query": query,
                "limit": limit,
                "score_threshold": score_threshold
            },
            timeout_ms=self.config.search_timeout_ms,
            api_key=self.config.qdrant_api_key
        )
        
        if not result:
            return []
        
        from kimi_proxy.core.models import QdrantSearchResult
        
        hits = result.get("hits", [])
        return [
            QdrantSearchResult(
                id=hit.get("id", ""),
                score=hit.get("score", 0.0),
                content_preview=hit.get("payload", {}).get("preview", "")[:200],
                full_content=hit.get("payload", {}).get("content", ""),
                metadata=hit.get("payload", {}).get("metadata", {}),
                vector=hit.get("vector")
            )
            for hit in hits
        ]
    
    async def store_vector(
        self, 
        content: str, 
        memory_type: str = "episodic",
        metadata: Optional[Dict[str, Any]] = None
    ) -> Optional[str]:
        """
        Stocke un vecteur mémoire dans Qdrant.
        
        Génère un ID unique basé sur le hash du contenu.
        
        Args:
            content: Contenu à stocker (texte)
            memory_type: Type de mémoire (episodic/frequent/semantic)
            metadata: Métadonnées additionnelles (optionnel)
            
        Returns:
            ID du vecteur stocké ou None si échec
            
        Example:
            >>> vector_id = await client.store_vector(
            ...     "J'ai débogué l'API ce matin",
            ...     memory_type="episodic",
            ...     metadata={"session_id": 1, "timestamp": "2026-02-18"}
            ... )
        """
        result = await self.rpc_client.make_rpc_call(
            server_url=self.config.qdrant_url,
            method="upsert",
            params={
                "collection": self.config.qdrant_collection,
                "points": [{
                    "id": self._generate_vector_id(content, memory_type),
                    "vector": None,  # Qdrant génère l'embedding
                    "payload": {
                        "content": content,
                        "preview": content[:200],
                        "type": memory_type,
                        "metadata": metadata or {},
                        "timestamp": datetime.now().isoformat()
                    }
                }]
            },
            timeout_ms=1000.0,
            api_key=self.config.qdrant_api_key
        )
        
        if not result:
            return None
        
        return result.get("id") if isinstance(result, dict) else None
    
    async def find_redundant(
        self, 
        content: str, 
        similarity_threshold: float = 0.85
    ) -> List[str]:
        """
        Détecte les mémoires redondantes (similarité élevée).
        
        Args:
            content: Contenu à vérifier
            similarity_threshold: Seuil de similarité (0-1, par défaut: 0.85)
            
        Returns:
            Liste des IDs de mémoires redondantes trouvées
            
        Example:
            >>> redundant = await client.find_redundant(
            ...     "J'ai débogué l'API ce matin",
            ...     similarity_threshold=0.90
            ... )
            >>> if redundant:
            ...     print(f"{len(redundant)} mémoires similaires trouvées")
        """
        similar = await self.search_similar(
            query=content[:500],  # Limite pour performance
            limit=10,
            score_threshold=similarity_threshold
        )
        return [s.id for s in similar if s.score >= similarity_threshold]
    
    async def cluster_memories(
        self, 
        session_id: int,
        min_cluster_size: int = 3
    ) -> List["MCPCluster"]:
        """
        Clusterise les mémoires d'une session par similarité.
        
        Performance: <2s pour 1000+ mémoires
        
        Args:
            session_id: ID de la session à clusteriser
            min_cluster_size: Nombre minimum de points par cluster (par défaut: 3)
            
        Returns:
            Liste des clusters avec leurs métriques
            
        Example:
            >>> clusters = await client.cluster_memories(session_id=42)
            >>> for cluster in clusters:
            ...     print(f"Topic: {cluster.topic_label}")
            ...     print(f"Cohesion: {cluster.cohesion_score:.2f}")
        """
        from kimi_proxy.core.models import MCPCluster
        
        result = await self.rpc_client.make_rpc_call(
            server_url=self.config.qdrant_url,
            method="cluster",
            params={
                "collection": self.config.qdrant_collection,
                "filter": {"session_id": session_id},
                "min_cluster_size": min_cluster_size
            },
            timeout_ms=2000.0,
            api_key=self.config.qdrant_api_key
        )
        
        if not result or not isinstance(result, dict):
            return []
        
        clusters = result.get("clusters", [])
        return [
            MCPCluster(
                id=c.get("id", ""),
                center_id=c.get("center_id", ""),
                memory_ids=c.get("point_ids", []),
                centroid=c.get("centroid"),
                cohesion_score=c.get("cohesion", 0.0),
                topic_label=c.get("topic", "")
            )
            for c in clusters
        ]
    
    def is_available(self) -> bool:
        """
        Vérifie si Qdrant est disponible (basé sur le cache).
        
        Returns:
            True si le dernier statut était connecté
        """
        return self._status is not None and self._status.connected
    
    def _generate_vector_id(self, content: str, memory_type: str) -> str:
        """
        Génère un ID unique pour le vecteur.
        
        Utilise hash pour générer un ID stable.
        
        Args:
            content: Contenu à stocker
            memory_type: Type de mémoire
            
        Returns:
            ID unique au format "type_hash32"
        """
        import hashlib
        content_hash = hashlib.md5(content.encode()).hexdigest()[:8]
        return f"{memory_type}_{content_hash}"
